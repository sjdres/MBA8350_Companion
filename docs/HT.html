<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Hypothesis Tests | MBA 8350: Analyzing and Leveraging Data   The Course Companion</title>
  <meta name="description" content="This is a course companion for MBA 8350." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Hypothesis Tests | MBA 8350: Analyzing and Leveraging Data   The Course Companion" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a course companion for MBA 8350." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Hypothesis Tests | MBA 8350: Analyzing and Leveraging Data   The Course Companion" />
  
  <meta name="twitter:description" content="This is a course companion for MBA 8350." />
  

<meta name="author" content="Scott Dressler" />


<meta name="date" content="2021-06-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="CI.html"/>
<link rel="next" href="SLR.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MBA 8350 Course Companion</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#about-this-book"><i class="fa fa-check"></i>About this book…</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-big-picture-of-statistics"><i class="fa fa-check"></i><b>1.1</b> The “Big Picture” of Statistics</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#the-vocabulary-of-statistics"><i class="fa fa-check"></i><b>1.2</b> The Vocabulary of Statistics</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#descriptive-measures"><i class="fa fa-check"></i><b>1.3</b> Descriptive Measures</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#central-tendency"><i class="fa fa-check"></i><b>1.3.1</b> Central Tendency</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#variation"><i class="fa fa-check"></i><b>1.3.2</b> Variation</a></li>
<li class="chapter" data-level="1.3.3" data-path="intro.html"><a href="intro.html#measures-of-shape"><i class="fa fa-check"></i><b>1.3.3</b> Measures of shape</a></li>
<li class="chapter" data-level="1.3.4" data-path="intro.html"><a href="intro.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.3.4</b> Covariance and Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Data.html"><a href="Data.html"><i class="fa fa-check"></i><b>2</b> Data Collection and Sampling</a>
<ul>
<li class="chapter" data-level="2.1" data-path="Data.html"><a href="Data.html#sampling-distributions"><i class="fa fa-check"></i><b>2.1</b> Sampling Distributions</a></li>
<li class="chapter" data-level="2.2" data-path="Data.html"><a href="Data.html#sampling-bias---two-examples"><i class="fa fa-check"></i><b>2.2</b> Sampling Bias - two examples</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="Data.html"><a href="Data.html#dewey-defeats-truman"><i class="fa fa-check"></i><b>2.2.1</b> Dewey Defeats Truman?</a></li>
<li class="chapter" data-level="2.2.2" data-path="Data.html"><a href="Data.html#section-1"><i class="fa fa-check"></i><b>2.2.2</b> 98.6?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="Data.html"><a href="Data.html#sampling-methods"><i class="fa fa-check"></i><b>2.3</b> Sampling Methods</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="Data.html"><a href="Data.html#simple-random-sampling"><i class="fa fa-check"></i><b>2.3.1</b> Simple random sampling</a></li>
<li class="chapter" data-level="2.3.2" data-path="Data.html"><a href="Data.html#systematic-sampling"><i class="fa fa-check"></i><b>2.3.2</b> Systematic Sampling</a></li>
<li class="chapter" data-level="2.3.3" data-path="Data.html"><a href="Data.html#stratified-sampling"><i class="fa fa-check"></i><b>2.3.3</b> Stratified Sampling</a></li>
<li class="chapter" data-level="2.3.4" data-path="Data.html"><a href="Data.html#cluster-sampling"><i class="fa fa-check"></i><b>2.3.4</b> Cluster Sampling</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="Data.html"><a href="Data.html#sampling-in-practice"><i class="fa fa-check"></i><b>2.4</b> Sampling in Practice</a></li>
<li class="chapter" data-level="2.5" data-path="Data.html"><a href="Data.html#sampling-and-sampling-distributions"><i class="fa fa-check"></i><b>2.5</b> Sampling and Sampling Distributions</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="Data.html"><a href="Data.html#an-application"><i class="fa fa-check"></i><b>2.5.1</b> An Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="R.html"><a href="R.html"><i class="fa fa-check"></i><b>3</b> Getting Started with R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="R.html"><a href="R.html#the-r-project-for-statistical-computing"><i class="fa fa-check"></i><b>3.1</b> The R Project for Statistical Computing</a></li>
<li class="chapter" data-level="3.2" data-path="R.html"><a href="R.html#downloading-and-installing-r"><i class="fa fa-check"></i><b>3.2</b> Downloading and installing R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="R.html"><a href="R.html#choosing-a-mirror"><i class="fa fa-check"></i><b>3.2.1</b> Choosing a <em>Mirror</em></a></li>
<li class="chapter" data-level="3.2.2" data-path="R.html"><a href="R.html#download-and-install-the-correct-version"><i class="fa fa-check"></i><b>3.2.2</b> Download and install the correct version</a></li>
<li class="chapter" data-level="3.2.3" data-path="R.html"><a href="R.html#downloading-and-installing-rstudio"><i class="fa fa-check"></i><b>3.2.3</b> Downloading and installing RStudio</a></li>
<li class="chapter" data-level="3.2.4" data-path="R.html"><a href="R.html#taking-stock"><i class="fa fa-check"></i><b>3.2.4</b> Taking Stock</a></li>
<li class="chapter" data-level="3.2.5" data-path="R.html"><a href="R.html#installing-packages"><i class="fa fa-check"></i><b>3.2.5</b> Installing <em>Packages</em></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="R.html"><a href="R.html#coding-basics"><i class="fa fa-check"></i><b>3.3</b> Coding Basics</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="R.html"><a href="R.html#assigning-objects"><i class="fa fa-check"></i><b>3.3.1</b> Assigning Objects</a></li>
<li class="chapter" data-level="3.3.2" data-path="R.html"><a href="R.html#listing-adding-and-removing"><i class="fa fa-check"></i><b>3.3.2</b> Listing, Adding, and Removing</a></li>
<li class="chapter" data-level="3.3.3" data-path="R.html"><a href="R.html#loading-data"><i class="fa fa-check"></i><b>3.3.3</b> Loading Data</a></li>
<li class="chapter" data-level="3.3.4" data-path="R.html"><a href="R.html#manipulating-data"><i class="fa fa-check"></i><b>3.3.4</b> Manipulating Data</a></li>
<li class="chapter" data-level="3.3.5" data-path="R.html"><a href="R.html#subsetting-data"><i class="fa fa-check"></i><b>3.3.5</b> Subsetting Data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="R.html"><a href="R.html#data-visualization"><i class="fa fa-check"></i><b>3.4</b> Data Visualization</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="R.html"><a href="R.html#histograms"><i class="fa fa-check"></i><b>3.4.1</b> Histograms</a></li>
<li class="chapter" data-level="3.4.2" data-path="R.html"><a href="R.html#line-bar-and-scatter-plots"><i class="fa fa-check"></i><b>3.4.2</b> Line, bar, and Scatter Plots</a></li>
<li class="chapter" data-level="3.4.3" data-path="R.html"><a href="R.html#boxplots"><i class="fa fa-check"></i><b>3.4.3</b> Boxplots</a></li>
<li class="chapter" data-level="3.4.4" data-path="R.html"><a href="R.html#much-more-out-there"><i class="fa fa-check"></i><b>3.4.4</b> Much more out there</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="CLT.html"><a href="CLT.html"><i class="fa fa-check"></i><b>4</b> The Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="4.1" data-path="CLT.html"><a href="CLT.html#the-clt-formally"><i class="fa fa-check"></i><b>4.1</b> The CLT (Formally)</a></li>
<li class="chapter" data-level="4.2" data-path="CLT.html"><a href="CLT.html#application-1-a-sampling-distribution-with-a-known-population"><i class="fa fa-check"></i><b>4.2</b> Application 1: A Sampling Distribution with a Known Population</a></li>
<li class="chapter" data-level="4.3" data-path="CLT.html"><a href="CLT.html#application-2-a-sampling-distribution-with-an-unknown-population"><i class="fa fa-check"></i><b>4.3</b> Application 2: A Sampling Distribution with an Unknown Population</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="CLT.html"><a href="CLT.html#the-sample"><i class="fa fa-check"></i><b>4.3.1</b> The Sample</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="CLT.html"><a href="CLT.html#the-punchline-1"><i class="fa fa-check"></i><b>4.4</b> The Punchline</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="CI.html"><a href="CI.html"><i class="fa fa-check"></i><b>5</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="5.1" data-path="CI.html"><a href="CI.html#a-refresher-on-probability"><i class="fa fa-check"></i><b>5.1</b> A Refresher on Probability</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="CI.html"><a href="CI.html#application-1"><i class="fa fa-check"></i><b>5.1.1</b> Application 1</a></li>
<li class="chapter" data-level="5.1.2" data-path="CI.html"><a href="CI.html#application-2"><i class="fa fa-check"></i><b>5.1.2</b> Application 2</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="CI.html"><a href="CI.html#deriving-a-confidence-interval"><i class="fa fa-check"></i><b>5.2</b> Deriving a Confidence Interval</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="CI.html"><a href="CI.html#application-3"><i class="fa fa-check"></i><b>5.2.1</b> Application 3</a></li>
<li class="chapter" data-level="5.2.2" data-path="CI.html"><a href="CI.html#what-if-we-want-to-change-confidence"><i class="fa fa-check"></i><b>5.2.2</b> What if we want to change confidence?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="CI.html"><a href="CI.html#what-to-do-when-we-do-not-know-sigma"><i class="fa fa-check"></i><b>5.3</b> What to do when we do not know <span class="math inline">\(\sigma\)</span></a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="CI.html"><a href="CI.html#t-distribution-versus-z-distribution"><i class="fa fa-check"></i><b>5.3.1</b> t distribution versus Z distribution…</a></li>
<li class="chapter" data-level="5.3.2" data-path="CI.html"><a href="CI.html#application-4"><i class="fa fa-check"></i><b>5.3.2</b> Application 4</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="CI.html"><a href="CI.html#determining-sample-size"><i class="fa fa-check"></i><b>5.4</b> Determining Sample Size</a></li>
<li class="chapter" data-level="5.5" data-path="CI.html"><a href="CI.html#concluding-applications"><i class="fa fa-check"></i><b>5.5</b> Concluding Applications</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="CI.html"><a href="CI.html#light-bulbs-last-time"><i class="fa fa-check"></i><b>5.5.1</b> Light Bulbs (Last Time)</a></li>
<li class="chapter" data-level="5.5.2" data-path="CI.html"><a href="CI.html#returning-to-the-philadelphia-school-policy-application"><i class="fa fa-check"></i><b>5.5.2</b> Returning to the Philadelphia School Policy Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="HT.html"><a href="HT.html"><i class="fa fa-check"></i><b>6</b> Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="6.1" data-path="HT.html"><a href="HT.html#anatomy-of-a-hypothesis-test"><i class="fa fa-check"></i><b>6.1</b> Anatomy of a Hypothesis Test</a></li>
<li class="chapter" data-level="6.2" data-path="HT.html"><a href="HT.html#two-methods-for-conducting-a-hypothesis-test-when-sigma-is-known"><i class="fa fa-check"></i><b>6.2</b> Two methods for conducting a hypothesis test (when <span class="math inline">\(\sigma\)</span> is known)</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="HT.html"><a href="HT.html#rejection-region-method"><i class="fa fa-check"></i><b>6.2.1</b> Rejection Region Method</a></li>
<li class="chapter" data-level="6.2.2" data-path="HT.html"><a href="HT.html#p-value-approach"><i class="fa fa-check"></i><b>6.2.2</b> P-value Approach</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="HT.html"><a href="HT.html#two-sided-vs-one-sided-test"><i class="fa fa-check"></i><b>6.3</b> Two-sided vs One-sided Test</a></li>
<li class="chapter" data-level="6.4" data-path="HT.html"><a href="HT.html#conducting-a-hypothesis-test-when-sigma-is-unknown"><i class="fa fa-check"></i><b>6.4</b> Conducting a hypothesis test (when <span class="math inline">\(\sigma\)</span> is unknown)</a></li>
<li class="chapter" data-level="6.5" data-path="HT.html"><a href="HT.html#appendix-a-note-on-calculating-p-values"><i class="fa fa-check"></i><b>6.5</b> Appendix: A note on calculating P-values</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="HT.html"><a href="HT.html#the-problem"><i class="fa fa-check"></i><b>6.5.1</b> The Problem</a></li>
<li class="chapter" data-level="6.5.2" data-path="HT.html"><a href="HT.html#how-to-calculate-p-values"><i class="fa fa-check"></i><b>6.5.2</b> How to calculate p-values</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="SLR.html"><a href="SLR.html"><i class="fa fa-check"></i><b>7</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="SLR.html"><a href="SLR.html#a-simple-linear-regression-model"><i class="fa fa-check"></i><b>7.1</b> A Simple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="SLR.html"><a href="SLR.html#what-does-a-regression-model-imply"><i class="fa fa-check"></i><b>7.1.1</b> What does a regression model imply?</a></li>
<li class="chapter" data-level="7.1.2" data-path="SLR.html"><a href="SLR.html#the-real-simple-linear-regression-model"><i class="fa fa-check"></i><b>7.1.2</b> The <em>REAL</em> Simple Linear Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="SLR.html"><a href="SLR.html#application-predicting-house-price-based-on-house-size"><i class="fa fa-check"></i><b>7.2</b> Application: Predicting House Price Based on House Size</a></li>
<li class="chapter" data-level="7.3" data-path="SLR.html"><a href="SLR.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>7.3</b> Ordinary Least Squares (OLS)</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="SLR.html"><a href="SLR.html#b.l.u.e."><i class="fa fa-check"></i><b>7.3.1</b> B.L.U.E.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="SLR.html"><a href="SLR.html#decomposition-of-variance"><i class="fa fa-check"></i><b>7.4</b> Decomposition of Variance</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="SLR.html"><a href="SLR.html#the-r2"><i class="fa fa-check"></i><b>7.4.1</b> The <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="7.4.2" data-path="SLR.html"><a href="SLR.html#what-is-a-good-r2"><i class="fa fa-check"></i><b>7.4.2</b> What is a <em>good</em> <span class="math inline">\(R^2\)</span>?</a></li>
<li class="chapter" data-level="7.4.3" data-path="SLR.html"><a href="SLR.html#standard-error-of-the-estimate"><i class="fa fa-check"></i><b>7.4.3</b> Standard Error of the Estimate</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="SLR.html"><a href="SLR.html#assumptions-of-the-linear-regression-model"><i class="fa fa-check"></i><b>7.5</b> Assumptions of the Linear Regression Model</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="SLR.html"><a href="SLR.html#linearity"><i class="fa fa-check"></i><b>7.5.1</b> Linearity</a></li>
<li class="chapter" data-level="7.5.2" data-path="SLR.html"><a href="SLR.html#independence-of-errors"><i class="fa fa-check"></i><b>7.5.2</b> Independence of Errors</a></li>
<li class="chapter" data-level="7.5.3" data-path="SLR.html"><a href="SLR.html#equal-variance"><i class="fa fa-check"></i><b>7.5.3</b> Equal Variance</a></li>
<li class="chapter" data-level="7.5.4" data-path="SLR.html"><a href="SLR.html#normality-of-errors"><i class="fa fa-check"></i><b>7.5.4</b> Normality of Errors</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="SLR.html"><a href="SLR.html#statistical-inference"><i class="fa fa-check"></i><b>7.6</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="SLR.html"><a href="SLR.html#confidence-intervals-around-population-parameters"><i class="fa fa-check"></i><b>7.6.1</b> Confidence Intervals (around population parameters)</a></li>
<li class="chapter" data-level="7.6.2" data-path="SLR.html"><a href="SLR.html#hypothesis-tests"><i class="fa fa-check"></i><b>7.6.2</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="7.6.3" data-path="SLR.html"><a href="SLR.html#confidence-intervals-around-forecasts"><i class="fa fa-check"></i><b>7.6.3</b> Confidence Intervals (around forecasts)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="MLR.html"><a href="MLR.html"><i class="fa fa-check"></i><b>8</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="MLR.html"><a href="MLR.html#application-explaining-house-price-in-a-multiple-regression"><i class="fa fa-check"></i><b>8.1</b> Application: Explaining house price in a multiple regression</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="MLR.html"><a href="MLR.html#the-importance-of-controls"><i class="fa fa-check"></i><b>8.1.1</b> The Importance of “Controls”</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="MLR.html"><a href="MLR.html#adjusted-r2"><i class="fa fa-check"></i><b>8.2</b> Adjusted <span class="math inline">\(R^2\)</span></a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="MLR.html"><a href="MLR.html#abusing-an-r2"><i class="fa fa-check"></i><b>8.2.1</b> Abusing an <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="8.2.2" data-path="MLR.html"><a href="MLR.html#an-adjusted-r2"><i class="fa fa-check"></i><b>8.2.2</b> An <em>Adjusted</em> <span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="MLR.html"><a href="MLR.html#qualitative-dummy-variables"><i class="fa fa-check"></i><b>8.3</b> Qualitative (Dummy) Variables</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="MLR.html"><a href="MLR.html#intercept-dummy-variable"><i class="fa fa-check"></i><b>8.3.1</b> Intercept dummy variable</a></li>
<li class="chapter" data-level="8.3.2" data-path="MLR.html"><a href="MLR.html#slope-dummy-variable"><i class="fa fa-check"></i><b>8.3.2</b> Slope dummy variable</a></li>
<li class="chapter" data-level="8.3.3" data-path="MLR.html"><a href="MLR.html#what-if-there-are-more-than-two-categories"><i class="fa fa-check"></i><b>8.3.3</b> What if there are more than two categories?</a></li>
<li class="chapter" data-level="8.3.4" data-path="MLR.html"><a href="MLR.html#a-final-application"><i class="fa fa-check"></i><b>8.3.4</b> A Final Application</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="MLR.html"><a href="MLR.html#joint-hypothesis-tests"><i class="fa fa-check"></i><b>8.4</b> Joint Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="MLR.html"><a href="MLR.html#simple-hypothesis-tests"><i class="fa fa-check"></i><b>8.4.1</b> Simple Hypothesis Tests</a></li>
<li class="chapter" data-level="8.4.2" data-path="MLR.html"><a href="MLR.html#simple-versus-joint-tests"><i class="fa fa-check"></i><b>8.4.2</b> Simple versus Joint Tests</a></li>
<li class="chapter" data-level="8.4.3" data-path="MLR.html"><a href="MLR.html#applications"><i class="fa fa-check"></i><b>8.4.3</b> Applications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Advanced.html"><a href="Advanced.html"><i class="fa fa-check"></i><b>9</b> Advanced Regression Topics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="Advanced.html"><a href="Advanced.html#nonlinear-models"><i class="fa fa-check"></i><b>9.1</b> Nonlinear Models</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="Advanced.html"><a href="Advanced.html#derivatives"><i class="fa fa-check"></i><b>9.1.1</b> Derivatives</a></li>
<li class="chapter" data-level="9.1.2" data-path="Advanced.html"><a href="Advanced.html#why-consider-non-linear-relationships"><i class="fa fa-check"></i><b>9.1.2</b> Why consider non-linear relationships?</a></li>
<li class="chapter" data-level="9.1.3" data-path="Advanced.html"><a href="Advanced.html#functional-forms"><i class="fa fa-check"></i><b>9.1.3</b> Functional Forms</a></li>
<li class="chapter" data-level="9.1.4" data-path="Advanced.html"><a href="Advanced.html#the-log-transformation"><i class="fa fa-check"></i><b>9.1.4</b> The Log transformation</a></li>
<li class="chapter" data-level="9.1.5" data-path="Advanced.html"><a href="Advanced.html#the-quadratic-transformation"><i class="fa fa-check"></i><b>9.1.5</b> The Quadratic transformation</a></li>
<li class="chapter" data-level="9.1.6" data-path="Advanced.html"><a href="Advanced.html#the-reciprocal-transformation"><i class="fa fa-check"></i><b>9.1.6</b> The Reciprocal transformation</a></li>
<li class="chapter" data-level="9.1.7" data-path="Advanced.html"><a href="Advanced.html#conclusion"><i class="fa fa-check"></i><b>9.1.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="Advanced.html"><a href="Advanced.html#collinearity"><i class="fa fa-check"></i><b>9.2</b> Collinearity</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="Advanced.html"><a href="Advanced.html#an-application-1"><i class="fa fa-check"></i><b>9.2.1</b> An Application</a></li>
<li class="chapter" data-level="9.2.2" data-path="Advanced.html"><a href="Advanced.html#what-does-collinearity-do-to-our-regression"><i class="fa fa-check"></i><b>9.2.2</b> What does Collinearity do to our regression?</a></li>
<li class="chapter" data-level="9.2.3" data-path="Advanced.html"><a href="Advanced.html#how-to-test-for-collinearity"><i class="fa fa-check"></i><b>9.2.3</b> How to test for Collinearity?</a></li>
<li class="chapter" data-level="9.2.4" data-path="Advanced.html"><a href="Advanced.html#an-application-2"><i class="fa fa-check"></i><b>9.2.4</b> An Application:</a></li>
<li class="chapter" data-level="9.2.5" data-path="Advanced.html"><a href="Advanced.html#how-do-we-remove-collinearity"><i class="fa fa-check"></i><b>9.2.5</b> How do we remove Collinearity?</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="Advanced.html"><a href="Advanced.html#heteroskedasticity"><i class="fa fa-check"></i><b>9.3</b> Heteroskedasticity</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="Advanced.html"><a href="Advanced.html#pure-versus-impure-heteroskedasticity"><i class="fa fa-check"></i><b>9.3.1</b> Pure versus Impure Heteroskedasticity</a></li>
<li class="chapter" data-level="9.3.2" data-path="Advanced.html"><a href="Advanced.html#consequences-of-heteroskedasticity"><i class="fa fa-check"></i><b>9.3.2</b> Consequences of Heteroskedasticity</a></li>
<li class="chapter" data-level="9.3.3" data-path="Advanced.html"><a href="Advanced.html#detection"><i class="fa fa-check"></i><b>9.3.3</b> Detection</a></li>
<li class="chapter" data-level="9.3.4" data-path="Advanced.html"><a href="Advanced.html#remedies"><i class="fa fa-check"></i><b>9.3.4</b> Remedies</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MBA 8350: Analyzing and Leveraging Data <br> The Course Companion</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="HT" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Hypothesis Tests</h1>
<p>Confidence intervals determine a range where our population mean resides given the characteristics of a sample and a desired level of confidence. Recall that the population parameter can be <em>anywhere</em> within the range dictated by a confidence interval.</p>
<p><strong>Hypothesis testing</strong> is a similar inferential method, but it approaches the problem from the opposite direction.</p>
<ol style="list-style-type: decimal">
<li><p>You start with an unambiguous claim on the value of the population parameter</p></li>
<li><p>You test to see if the sample statistics are consistent with the claim (or refute it)</p></li>
</ol>
<p>The general idea is that you begin with some <em>nonarbitrary</em> statement on what value you believe (or do not believe) the population parameter to be. You then test if the characteristics of your sample suggest that it is likely or not that a population with your proposed parameter values generated a sample like the one you currently have.</p>
<p>If this seems a bit vague at the moment. It will be more concrete soon. The main thing to keep in mind is that hypothesis tests are quite simple and structured. Once you learn how to perform one hypothesis test - you essentially can perform them all. This chapter guides you through some basic steps that once mastered - you’ll have a powerful tool of statistical inference under your belt.</p>
<div id="anatomy-of-a-hypothesis-test" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Anatomy of a Hypothesis Test</h2>
<p>A hypothesis test begins with a claim about the value of particular a population parameter.</p>
<p>This statement takes the form of a <strong>null hypothesis</strong>
<span class="math display">\[H_0 : \mu = x\]</span></p>
<p>This statement gets contrasted against an <strong>alternative hypothesis</strong></p>
<p><span class="math display">\[H_1 : \mu \neq x\]</span></p>
<p>The null hypothesis <span class="math inline">\((H_0)\)</span> represents a belief of a population parameter that you would like to <em>disprove</em>, while the alternative hypothesis <span class="math inline">\((H_1)\)</span> is the opposite of the null and represents a claim you would like to show.</p>
<p>A hypothesis test uses the characteristics of the sample to determine if the statement about the population parameter in the null appears consistent (or inconsistent) with the characteristics of the sample. Recall that we are still under the assumption that the characteristics of the sample are similar to the <strong>true</strong> characteristics of the population. Therefore, if the sample characteristics are inconsistent with the statement in the null hypothesis, then you are likely to <strong>reject the null hypothesis</strong>. This means that the null hypothesis does not capture the <strong>true</strong> characteristics of the population. If the sample characteristics are <em>similar</em> to those stated in the null hypothesis, then you do not have evidence to reject the null and you conclude to <strong>not reject the null hypothesis</strong>.</p>
<p>In other words, if you <em>reject the null</em>, you have statistical evidence that <span class="math inline">\(H_1\)</span> is correct (and the null hypothesis cannot be correct). If you <em>do not reject the null</em>, you have failed to prove the alternative hypothesis. Note that failure to prove the alternative does NOT mean that you have proven the null. In other words, there IS a difference between <em>do not reject</em> and <em>accept</em>!</p>
<p>This distinction between <em>do not reject</em> and <em>accept</em> cannot be emphasized enough. First, if anyone concludes that they accept the null in this class - you will get marked incorrect. If you conclude to accept the null outside of this class - then people will suspect that you don’t fully understand what you are talking about. Second, we can never say accept the null because it is simply too strong of a statement to make regarding a population parameter.</p>
<p>Suppose we believe that the population mean life span of our light bulbs is <span class="math inline">\(x\)</span> hours. A hypothesis test will give us a specific way of testing this belief, and allows us to conclude whether or not this statement is consistent with our sample.</p>
<p><span class="math display">\[H_0:\mu=x \quad versus \quad H_1:\mu\neq x\]</span></p>
<p>We will discuss how to formally conduct a hypothesis tests in a bit. For now, lets compare these hypotheses with the confidence interval we calculated in the previous section.</p>
<p><span class="math display">\[887 \leq \mu \leq 928\]</span></p>
<p>Recall that our confidence interval states that with 95% confidence, the population average life span of the light bulbs is <em>somewhere</em> between 887 hours and 928 hours - meaning that any value within this range is equally likely. It also states that there is only a 5% chance that the population parameter lies outside of this range.</p>
<p>If we were to test that the population average lifespan was 1000 hours,</p>
<p><span class="math display">\[H_0:\mu=1000 \quad versus \quad H_1:\mu\neq 1000\]</span></p>
<p>then our confidence interval would give us evidence to <strong>reject</strong> the null because there would be less than a 5% chance for the null to be true. The sample characteristics and and the statement in the null hypothesis are therefore inconsistent.</p>
<p>If we were to test that the population average lifespan was 900 hours, then we will reach a different conclusion.</p>
<p><span class="math display">\[H_0:\mu=900 \quad versus \quad H_1:\mu\neq 900\]</span></p>
<p>Since 900 is a value <em>inside</em> our confidence interval,then we would not have evidence to reject the null and we therefore conclude <strong>do not reject</strong> the null. The reason why we never say accept is that while 900 is within the confidence interval, there are also a <em>continuum</em> of other values in there. The true population mean might be 901, 900.0001, 910, etc. If you were to <em>accept</em> the null, then you are explicitly stating that the population parameter is exactly 900 - we do not have enough evidence for this.</p>
<p>Note that while we are seeing a clear connection between hypothesis tests and confidence intervals, hypothesis tests can get more sophisticated than this. It is therefore worthwhile to consider a formal solution methodology.</p>
</div>
<div id="two-methods-for-conducting-a-hypothesis-test-when-sigma-is-known" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Two methods for conducting a hypothesis test (when <span class="math inline">\(\sigma\)</span> is known)</h2>
<p>We will consider two equivalent methods for conducting a hypothesis test. The first is called the <em>rejection region</em> method and is very similar to confidence intervals. The second is the <em>p-value</em> method and delivers some very useful results that we will be using for the rest of the course. We will consider these methods in turn.</p>
<div id="rejection-region-method" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Rejection Region Method</h3>
<p>All hypothesis tests start with a statement of the null and alternative hypotheses. The null makes an explicit statement regarding the value of a population parameter <span class="math inline">\((\mu)\)</span>. Once this value of <span class="math inline">\(\mu\)</span> is established under the null, all hypothesis tests construct a <em>test statistic under the null</em>. In particular, assuming we know the population standard deviation <span class="math inline">\(\sigma\)</span>, we can construct a <em>Z statistic under the null</em> using our familiar z-transformation:</p>
<p><span class="math display">\[Z = \frac{\bar{X}-\mu}{\left(\sigma / \sqrt{n} \right)}\]</span></p>
<p>Note that we already know values from the sample <span class="math inline">\((\bar{X},\;n,\;\sigma)\)</span> and we have a <em>hypothesized</em> value of <span class="math inline">\(\mu\)</span> from the null hypothesis. We can therefore directly calculate this Z-value <em>under the null</em>. This would be the value of a Z-statistic given our sample characteristics under the <em>assumption</em> that our null hypothesis is correct.</p>
<p>The rejection region method takes this Z-statistic under the null and sees where it falls in a standard normal sampling distribution. The sampling distribution of a test statistic is first divided into two regions…</p>
<ol style="list-style-type: decimal">
<li><p>A region of rejection (a.k.a., critical region) - values of the test statistic that are unlikely to occur if the null hypothesis is true.</p></li>
<li><p>A region of nonrejection - values of the test statistic that are likely to occur if the null hypothesis is true, so they are <em>consistent with the null hypothesis</em>.</p></li>
</ol>
<p>The regions of rejection and nonrejection are identified by determining <em>critical values</em> of the test statistic. These are particular values of the sampling distribution that divides the entire distribution into rejection and nonrejection regions. This is why some people refer to the <em>rejection region</em> approach as the <em>critical value</em> approach.</p>
<p>Once the different regions are established, then you simply see where the calculated test statistic under the null falls. If it falls inside the rejection region, then you <strong>reject the null</strong> because the characteristics of the sample are <em>too inconsistent</em> with the population parameter stated inside the null hypothesis. If it falls inside the nonrejection region, then you <strong>do not reject the null</strong> because the characteristics of the sample are such that the population parameter stated inside the null is <em>possible</em> (but we can’t say if it’s necessarily true).</p>
<div id="the-steps-of-a-hypothesis-test-rejection-region-method" class="section level4" number="6.2.1.1">
<h4><span class="header-section-number">6.2.1.1</span> The Steps of a Hypothesis Test (Rejection Region Method)</h4>
<ol style="list-style-type: decimal">
<li><p>State the null and alternative hypotheses</p></li>
<li><p>Calculate a test statistic under the null</p></li>
<li><p>Determine the rejection and nonrejection regions of a standardized sampling distribution</p></li>
<li><p>Conclude (reject or do not reject)</p></li>
</ol>
</div>
<div id="application-1-1" class="section level4" number="6.2.1.2">
<h4><span class="header-section-number">6.2.1.2</span> Application 1</h4>
<p>Suppose a fast-food manager wants to determine whether the waiting time to place an order has changed from the previous mean of 4.5 minutes. We want to see if our sample characteristics are consistent with an average of 4.5 minutes or not. We start with a statement of the two hypotheses.</p>
<p><span class="math display">\[H_0:\mu=4.5 \quad versus \quad H_1:\mu\neq 4.5\]</span></p>
<p>The null explicitly states that <span class="math inline">\(\mu=4.5\)</span>, so we can use this value to construct a test statistic using the information from our sample. Suppose that a sample of <span class="math inline">\(n=25\)</span> observations delivered a sample mean of <span class="math inline">\(\bar{X}=5.1\)</span> minutes. Suppose further that we know the population standard deviation of the wait time process to be <span class="math inline">\(\sigma=1.2\)</span>. We can calculate a test statistic under the null.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="HT.html#cb138-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">=</span> <span class="fl">4.5</span></span>
<span id="cb138-2"><a href="HT.html#cb138-2" aria-hidden="true" tabindex="-1"></a>Xbar <span class="ot">=</span> <span class="fl">5.1</span></span>
<span id="cb138-3"><a href="HT.html#cb138-3" aria-hidden="true" tabindex="-1"></a>Sig <span class="ot">=</span> <span class="fl">1.2</span></span>
<span id="cb138-4"><a href="HT.html#cb138-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">25</span></span>
<span id="cb138-5"><a href="HT.html#cb138-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-6"><a href="HT.html#cb138-6" aria-hidden="true" tabindex="-1"></a>(<span class="at">Zstat =</span> (Xbar <span class="sc">-</span> mu)<span class="sc">/</span>(Sig<span class="sc">/</span><span class="fu">sqrt</span>(n)))</span></code></pre></div>
<pre><code>## [1] 2.5</code></pre>
<p><span class="math display">\[ Z = \frac{\bar{X}-\mu}{\left(\sigma / \sqrt{n} \right)} = \frac{5.1-4.5}{\left(1.2 / \sqrt{25} \right)} = 2.5\]</span></p>
<p>The next step involves taking a standard normal sampling distribution and breaking it up into regions of rejection and nonrejection. Before we do this, lets take a step back and think about what it means for a sample to be consistent or inconsistent with the null hypothesis. If you had a sample average <span class="math inline">\((\bar{X})\)</span> that was the same value as the parameter value stated in the null hypothesis <span class="math inline">\((\mu)\)</span> then you could state that the value of <span class="math inline">\(\mu\)</span> in the null hypothesis is <em>very consistent</em> with the characteristics of the sample. In fact, you can’t be more consistent than having <span class="math inline">\(\bar{X}\)</span> and <span class="math inline">\(\mu\)</span> being the exact same number. Furthermore, a test statistic under the null would be equal to zero because <span class="math inline">\((\bar{X}-\mu)\)</span> is in the numerator. This implies that a test statistic under the null equal to zero is very consistent with the null hypothesis, and you will therefore <em>not reject</em> the null hypothesis. However, the farther away the test statistic under the null gets from zero, the farther away it gets from the center of the <em>do not reject region</em> and the closer it gets to the <em>rejection regions</em>.</p>
<p>Lets illustrate this supposing that we want to test the hypothesis at the 95% confidence level <span class="math inline">\((\alpha=0.05)\)</span>. The central 95% of a standard normal distribution is given by</p>
<p><span class="math display">\[Pr(-1.96 \leq Z \leq 1.96) = 0.95\]</span></p>
<p>This means that if you reached into a bowl of numbers comprising a standard normal distribution, then 95% of the time you will draw a number between -1.96 and 1.96. The remaining numbers outside of this range will show up only 5% of the time. These regions are the bases for confidence intervals and also the bases for the nonrejection and rejection regions.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-84-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The yellow-shaded region is centered on zero and represents the <em>nonrejection region</em>. It tells you that if you calculate a test statistic under the null to be between -1.96 and 1.96, then you do not have enough evidence to reject the null. However, the green-shaded regions are the <em>rejection regions</em>. It tells you that if you calculate a test statistic under the null that is greater than 1.96 or less than -1.96, then you have enough evidence to reject the null (with 95% confidence). In other words, it is so unlikely to have the null be correct while simultaneously randomly selecting a sample with the observed sample characteristics, then we conclude that the statement in the null cannot be true. In the fast food example above, the test statistic under the null of 2.5 falls in the rejection region. This means that we can <em>reject</em> the null hypothesis of <span class="math inline">\(\mu=4.5\)</span> minutes with 95% confidence. In other words, we are 95% confident that the population mean is some number other than 4.5 minutes.</p>
<p><strong>Changing the level of confidence <span class="math inline">\((\alpha)\)</span></strong></p>
<p>The hypothesis test above was concluded under a specified 95% confidence level <span class="math inline">\((\alpha=0.05)\)</span>. This level of confidence effectively delivered our rejection and nonrejection regions. So… what happens when we change <span class="math inline">\(\alpha\)</span>?</p>
<p>The first thing to understand is that the level of confidence does not impact the hypotheses or the test statistic under the null. The <strong>only</strong> thing the level of confidence impacts is the shaded regions in the sampling distribution. The figure below illustrates rejection and nonrejection regions for <span class="math inline">\(\alpha\)</span> values of 0.10, 0.05, and 0.01. Note that as <span class="math inline">\(\alpha\)</span> gets smaller, the size of the nonrejection region gets larger. This means that <em>do not reject</em> is becoming a more likely conclusion. This should make sense because <em>do not reject</em> is a wishy-washy conclusion, while <em>reject</em> is definitive. Do not reject states that the null may or may not be true - it’s a punt! Therefore, if you are placing more confidence on your conclusion, the more likely you are to make the wishy washy conclusion.</p>
<p>The fast food example had a test statistic under the null of 2.5. This test statistic falls in the rejection region for both 90% and 95% levels of confidence. This suggests that if you can reject a null hypothesis with a certain level of confidence, then you can automatically reject at all lower levels of confidence. However, the do not reject region under 99% confidence is given by
<span class="math display">\[Pr(-2.58 \leq Z \leq 2.58)=0.99\]</span>
and our test statistic of 2.5 falls inside it. We therefore conclude that we <em>do NOT reject</em> the null with 99% confidence. In other words, we do not have enough evidence to say that the null hypothesis is incorrect at 99% confidence, so we conclude that it may or may not be true (i.e., we punt).</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-85-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Using the rejection region method, we were able to reject the null with 95% confidence <span class="math inline">\((\alpha=0.05)\)</span> but unable to reject with 99% confidence <span class="math inline">\((\alpha=0.01)\)</span>. This begs the question as to the highest confidence level at which we can reject the null. We know it is some confidence level between 95% and 99%, but what is it exactly? We can use the rejection region approach multiple times by choosing various values of <span class="math inline">\(\alpha\)</span> and narrow things down, or we can conduct the hypothesis test using the <em>p-value</em> approach.</p>
</div>
</div>
<div id="p-value-approach" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> P-value Approach</h3>
<p>The P-value is an extremely useful and often misunderstood number. I therefore have THREE equivalent ways of explaining it. Each one works - so just stick with the one that works for you. Before we get to those, lets talk explicitly about what we mean when we make statements based on confidence.</p>
<p>When using a sample statistic to draw conclusions about a population parameter, there is always the risk of reaching an incorrect conclusion. In other words, you can make an <strong>error</strong>.</p>
<p>When making a conclusion about a hypothesis test, one can either reject a null hypothesis or not. Therefore, there are two possible types of errors to be made.</p>
<ol style="list-style-type: decimal">
<li><p>A <strong>Type I error</strong> occurs when a researcher incorrectly rejects a true hypothesis. (<em>You rejected something that shouldn’t have been rejected.</em>)</p></li>
<li><p>A <strong>Type II error</strong> occurs when a researcher incorrectly fails to reject a false hypothesis. (<em>You did not reject something that you should have.</em>)</p></li>
</ol>
<p>The <strong>acceptable</strong> probability of committing either one of these errors depends upon an arbitrary confidence level <span class="math inline">\(\alpha\)</span>. To be precise, when you reject a hypothesis with 95% confidence, then you are implicitly stating that you are accepting a 5% chance of being wrong. That is where <span class="math inline">\(\alpha=0.05\)</span> (or 5% comes from). If you decrease <span class="math inline">\(\alpha\)</span> to 0.01 (or 1%), then you can reject a hypothesis with 99% confidence and implicitly accept a 1% chance of being wrong. The kicker is that the more you decrease the probability of committing a type I error, the more you increase the chance of not rejecting a hypothesis that you should be rejecting (a type II error). For example, if you want a conclusion with 100% confidence, then you will <em>never</em> reject a hypothesis no matter how wrong it actually is.</p>
<p>The main take away from the previous statement is that <span class="math inline">\(\alpha\)</span> states the <em>acceptable</em> probability of committing a type one error. Recall in our fast food example that we rejected the null hypothesis with 95% confidence (i.e., a 5% acceptable probability of being wrong ), but we did not reject the null hypothesis with 99% confidence (i.e., a 1% acceptable probability of being wrong ). This means that the <em>actual</em> probability of committing a type one error is somewhere in between 0.05 and 0.01 (i.e., 5% and 1%). This actual probability of committing a type I error is called the <strong>p-value</strong>.</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="HT.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fast Food Example Revisited</span></span>
<span id="cb140-2"><a href="HT.html#cb140-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">=</span> <span class="fl">4.5</span></span>
<span id="cb140-3"><a href="HT.html#cb140-3" aria-hidden="true" tabindex="-1"></a>Xbar <span class="ot">=</span> <span class="fl">5.1</span></span>
<span id="cb140-4"><a href="HT.html#cb140-4" aria-hidden="true" tabindex="-1"></a>Sig <span class="ot">=</span> <span class="fl">1.2</span></span>
<span id="cb140-5"><a href="HT.html#cb140-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">25</span></span>
<span id="cb140-6"><a href="HT.html#cb140-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-7"><a href="HT.html#cb140-7" aria-hidden="true" tabindex="-1"></a>(<span class="at">Zstat =</span> (Xbar <span class="sc">-</span> mu)<span class="sc">/</span>(Sig<span class="sc">/</span><span class="fu">sqrt</span>(n)))</span></code></pre></div>
<pre><code>## [1] 2.5</code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="HT.html#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence:</span></span>
<span id="cb142-2"><a href="HT.html#cb142-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.05</span></span>
<span id="cb142-3"><a href="HT.html#cb142-3" aria-hidden="true" tabindex="-1"></a>(<span class="at">Zcrit =</span> <span class="sc">-</span><span class="fu">qnorm</span>(alpha<span class="sc">/</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="HT.html#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 99% confidence:</span></span>
<span id="cb144-2"><a href="HT.html#cb144-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.01</span></span>
<span id="cb144-3"><a href="HT.html#cb144-3" aria-hidden="true" tabindex="-1"></a>(<span class="at">Zcrit =</span> <span class="sc">-</span><span class="fu">qnorm</span>(alpha<span class="sc">/</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 2.575829</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="HT.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># p-value:</span></span>
<span id="cb146-2"><a href="HT.html#cb146-2" aria-hidden="true" tabindex="-1"></a>(<span class="at">Pval =</span> <span class="fu">pnorm</span>(Zstat,<span class="at">lower.tail =</span> <span class="cn">FALSE</span>)<span class="sc">*</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.01241933</code></pre>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="HT.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Actual confidence level:</span></span>
<span id="cb148-2"><a href="HT.html#cb148-2" aria-hidden="true" tabindex="-1"></a>((<span class="dv">1</span><span class="sc">-</span>Pval)<span class="sc">*</span><span class="dv">100</span>)</span></code></pre></div>
<pre><code>## [1] 98.75807</code></pre>
<p>The calculations regarding the fast food example were repeated and continued to include a p-value. Recall that the null hypothesis stated that the population mean was equal to 4.5, and the test statistic under the null is equal to 2.5. The critical values marking the boundaries between the do not reject region and the reject regions was <span class="math inline">\(\pm 1.96\)</span> for <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(\pm 2.58\)</span> for <span class="math inline">\(\alpha=0.01\)</span>. Our test statistic falls inside the rejection region for <span class="math inline">\(\alpha=0.05\)</span> and inside the nonrejection region for <span class="math inline">\(\alpha=0.01\)</span>. Our test statistic falls <em>right on the boundary</em> of a rejection and nonrejection region when <span class="math inline">\(p=0.0124\)</span>. This is the p-value of the problem. It states that you can reject the null hypothesis with <em>at most</em> 98.76% confidence and you will incur a 1.24% chance of being wrong. As expected, it is between 5% and 1% and gives you a tailor-made confidence interval for the hypothesis test at hand.</p>
<div id="the-definitions-of-a-p-value" class="section level4" number="6.2.2.1">
<h4><span class="header-section-number">6.2.2.1</span> The definitions of a P-value</h4>
<blockquote>
<p>The p-value is the probability of getting a test statistic equal to or more extreme than the sample result, given that the null hypothesis <span class="math inline">\((H_0)\)</span> is true.</p>
</blockquote>
<p>While this is the technical definition of a p-value, it is a bit vague. There are some roughly equivalent definitions that might be easier to digest.</p>
<ol style="list-style-type: decimal">
<li><p>The p-value is the probability of committing a Type I error. If the p-value is greater than some arbitrarily given <span class="math inline">\(\alpha\)</span>, then you cannot reject the null.</p></li>
<li><p>The p-value is the probability that your null hypothesis is <em>correct</em>. The HIGHEST level of confidence at which you can reject the null is <span class="math inline">\(1-p\)</span>.</p></li>
</ol>
<hr />
</div>
</div>
</div>
<div id="two-sided-vs-one-sided-test" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Two-sided vs One-sided Test</h2>
<p><span class="math display">\[H_0:\mu=4.5 \quad versus \quad H_1:\mu\neq 4.5\]</span></p>
<p>The hypothesis test considered above is known as a <strong>two-sided</strong> test because the null gets rejected if the mean of the sample is either significantly greater than or less than the value stated in the null hypothesis. If you notice from the illustrations above, a two-sided test has <strong>TWO</strong> rejection regions - one in each tail (hence the name). Note that this is also why we calculated critical values using half of the value of <span class="math inline">\(\alpha\)</span> and doubled the calculated probability value in order to arrive at a p-value.</p>
<p>In the fast food example above, suppose we want to show that the service time <em>increased</em>. In other words, we want statistical evidence that the wait time actually increased from a previous time of 4.5 minutes. We can provide statistical evidence by rejecting a null hypothesis that the new population average wait time is 4.5 minutes <em>or less</em>. This scenario delivers us a <strong>one-sided hypothesis test</strong>.</p>
<p><span class="math display">\[H_0:\mu \leq 4.5 \quad versus \quad H_1:\mu&gt; 4.5\]</span></p>
<p>As the name implies, a one-sided hypothesis test only has one rejection region. This means that the entire value of <span class="math inline">\(\alpha\)</span> is grouped into either the right or left tail. The tail containing the rejection region depends upon the exact specification of the hypothesis test.</p>
<p>The hypothesis test above is called a <em>right-tailed</em> test because the rejection region is in the right tail. To see this, consider several hypothetical sample averages and see if they are consistent with the null <span class="math inline">\(\mu \leq 4.5\)</span>.</p>
<ul>
<li><p>Suppose you observe <span class="math inline">\(\bar{X}=4\)</span>. Is this sample average consistent with <span class="math inline">\(\mu \leq 4.5\)</span>?</p></li>
<li><p>What about <span class="math inline">\(\bar{X}=2\)</span>?</p></li>
<li><p>What about <span class="math inline">\(\bar{X}=1\)</span>?</p></li>
</ul>
<p>Your answer should be yes to all of these sample averages. In fact, <em>any</em> sample average less than or equal to 4.5 is consistent with <span class="math inline">\(\mu \leq 4.5\)</span>.</p>
<p>Next, recall the test statistic under the null:</p>
<p><span class="math display">\[ Z = \frac{\bar{X}-4.5}{\left(\sigma / \sqrt{n} \right)}\]</span></p>
<p>For any of the hypothetical values considered above (4, 2, or 1), the test statistic would be a negative number. Since we said that all of these sample averages are consistent with the null being true, then we would never reject the null in any of these instances. Therefore, the rejection region cannot be in the left tail because that is where the negative values of the distribution reside. The rejection region must therefore be in the right tail. Only when a sample average is sufficiently greater than 4.5 is when we can consider rejecting the null.</p>
<p>Now that we already have the null and alternative hypotheses down as well as the test statistic under the null, the next step is to determine the critical value that divides the distribution into rejection and nonregection regions.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="HT.html#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fast Food Example Revisited</span></span>
<span id="cb150-2"><a href="HT.html#cb150-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">=</span> <span class="fl">4.5</span></span>
<span id="cb150-3"><a href="HT.html#cb150-3" aria-hidden="true" tabindex="-1"></a>Xbar <span class="ot">=</span> <span class="fl">5.1</span></span>
<span id="cb150-4"><a href="HT.html#cb150-4" aria-hidden="true" tabindex="-1"></a>Sig <span class="ot">=</span> <span class="fl">1.2</span></span>
<span id="cb150-5"><a href="HT.html#cb150-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">25</span></span>
<span id="cb150-6"><a href="HT.html#cb150-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-7"><a href="HT.html#cb150-7" aria-hidden="true" tabindex="-1"></a>(<span class="at">Zstat =</span> (Xbar <span class="sc">-</span> mu)<span class="sc">/</span>(Sig<span class="sc">/</span><span class="fu">sqrt</span>(n)))</span></code></pre></div>
<pre><code>## [1] 2.5</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="HT.html#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence:</span></span>
<span id="cb152-2"><a href="HT.html#cb152-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.05</span></span>
<span id="cb152-3"><a href="HT.html#cb152-3" aria-hidden="true" tabindex="-1"></a>(<span class="at">Zcrit =</span> <span class="sc">-</span><span class="fu">qnorm</span>(alpha))</span></code></pre></div>
<pre><code>## [1] 1.644854</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="HT.html#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P-value:</span></span>
<span id="cb154-2"><a href="HT.html#cb154-2" aria-hidden="true" tabindex="-1"></a>(<span class="at">Pval =</span> <span class="fu">pnorm</span>(Zstat,<span class="at">lower.tail=</span><span class="cn">FALSE</span>))</span></code></pre></div>
<pre><code>## [1] 0.006209665</code></pre>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="HT.html#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="co"># highest Confidence Level for rejection:</span></span>
<span id="cb156-2"><a href="HT.html#cb156-2" aria-hidden="true" tabindex="-1"></a>((<span class="dv">1</span><span class="sc">-</span>Pval)<span class="sc">*</span><span class="dv">100</span>)</span></code></pre></div>
<pre><code>## [1] 99.37903</code></pre>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-88-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>If we conducted this hypothesis test at the 95% confidence level ($), you will see that the rejection region is the 5% of the curve in the right tail. That means you reject all test statistics greater than or equal to 1.64. Since our test statistic is 2.5, we can reject with 95% confidence. We can also conduct this hypothesis test using the p-value approach which delivers a p-value of 0.0062. This means that if we reject the null, we only incur a 0.62% chance of being wrong. This equivalently means that we can reject the null with up to 99.38% confidence.</p>
</div>
<div id="conducting-a-hypothesis-test-when-sigma-is-unknown" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Conducting a hypothesis test (when <span class="math inline">\(\sigma\)</span> is unknown)</h2>
<p>When the population standard deviation <span class="math inline">\((\sigma)\)</span> is unknown, it must be estimated. Just like with confidence intervals, When you replace <span class="math inline">\(\sigma\)</span> with it’s estimate <span class="math inline">\(S\)</span>, you change the distribution from Z to t (and need to mind the degrees of freedom).</p>
<p><strong>That’s the only difference</strong></p>
<p>Let’s go through some applications when <span class="math inline">\(\sigma\)</span> is unknown. You will see that the only difference is that we use a t distribution with <span class="math inline">\(n-1\)</span> degrees of freedom to calculate rejection / nonrejection regions and p-values.</p>
<div id="application-2-1" class="section level4" number="6.4.0.1">
<h4><span class="header-section-number">6.4.0.1</span> Application 2</h4>
<p>The Saxon Home Improvement Co. has had a mean per sales invoice of $120 over the last 5 years and would like to know if the mean amount per sales invoice has significantly changed. This is enough information to state our hypotheses for a two-sided test.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p><span class="math display">\[H_0:\mu=120 \quad versus \quad H_0:\mu \neq 120\]</span></p>
<p>You collected a sample of 12 observations, and concluded that the sample mean was $112.85 and the sample standard deviation was $20.80.</p>
<p><span class="math display">\[\bar{X}=112.85, \quad n=12, \quad S=20.80\]</span></p>
<p>This information allows us to calculate a t-test statistic under the null. The only difference is that we now have a sample standard deviation <span class="math inline">\((S)\)</span> were we once had a population standard deviation <span class="math inline">\((\sigma)\)</span>.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="HT.html#cb158-1" aria-hidden="true" tabindex="-1"></a>Xbar <span class="ot">=</span> <span class="fl">112.85</span></span>
<span id="cb158-2"><a href="HT.html#cb158-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">12</span></span>
<span id="cb158-3"><a href="HT.html#cb158-3" aria-hidden="true" tabindex="-1"></a>S <span class="ot">=</span> <span class="fl">20.80</span></span>
<span id="cb158-4"><a href="HT.html#cb158-4" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">=</span> <span class="dv">120</span></span>
<span id="cb158-5"><a href="HT.html#cb158-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb158-6"><a href="HT.html#cb158-6" aria-hidden="true" tabindex="-1"></a>(<span class="at">t =</span> (Xbar <span class="sc">-</span> mu) <span class="sc">/</span> (S<span class="sc">/</span><span class="fu">sqrt</span>(n)))</span></code></pre></div>
<pre><code>## [1] -1.190785</code></pre>
<p><span class="math display">\[ t = \frac{\bar{X}-\mu}{\left(S / \sqrt{n} \right)}=\frac{112.85-120}{\left(20.80 / \sqrt{12} \right)}=-1.19\]</span></p>
<p>Now that we have our test statistic, we need to determine if it falls into our nonrejection or rejection regions. The important thing to realize is that these regions are now part of a t distribution with 11 <span class="math inline">\((n-1)\)</span> degrees of freedom. If we consider 95% confidence…</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="HT.html#cb160-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.05</span></span>
<span id="cb160-2"><a href="HT.html#cb160-2" aria-hidden="true" tabindex="-1"></a>(<span class="at">tcrit =</span> <span class="sc">-</span><span class="fu">qt</span>(alpha<span class="sc">/</span><span class="dv">2</span>,n<span class="dv">-1</span>))</span></code></pre></div>
<pre><code>## [1] 2.200985</code></pre>
<p>The calculations suggest that the nonrejection region is between <span class="math inline">\(\pm 2.2\)</span>. Since our test statistic falls within this region, we do not reject the null. This implies that we do not have evidence that the population average sales invoice has significantly changed from $120 with 95% confidence. The conclusion is therefore <em>do not reject</em>.</p>
<p>We could also calculate a p-value for the test:</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="HT.html#cb162-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">Pval =</span> <span class="fu">pt</span>(t,n<span class="dv">-1</span>)<span class="sc">*</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.2588003</code></pre>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="HT.html#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Highest confidence interval for rejection:</span></span>
<span id="cb164-2"><a href="HT.html#cb164-2" aria-hidden="true" tabindex="-1"></a>((<span class="dv">1</span><span class="sc">-</span>Pval)<span class="sc">*</span><span class="dv">100</span>)</span></code></pre></div>
<pre><code>## [1] 74.11997</code></pre>
<p>Notice here that the p-value states that if we were to reject the null, then we would incur a 25.88% chance of being wrong. This means that we could only reject the null with 74.12% confidence.</p>
<p>Note that the calculations uses a new R command: <code>pt(q,df)</code>. This command calculates the probability under a t distribution the same way the <code>pnorm(q)</code> command calculates the probability under a standard normal distribution. In addition, I again encourage you to always visualize the distribution and explicitly draw the rejection and nonrejection regions. This is extremely helpful when first getting started. Below you will also see a note I wrote for a previous class reinforcing how R likes to calculate probabilities. It is for reference if needed.</p>
</div>
</div>
<div id="appendix-a-note-on-calculating-p-values" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Appendix: A note on calculating P-values</h2>
<div id="the-problem" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> The Problem</h3>
<p>Suppose you were performing a right-tailed hypothesis test (using a t distribution) and you arrived at a test statistics under the null of <span class="math inline">\(1.57\)</span>. This means that the rejection region is in the right tail, and if you wished to calculate the p-value, then it would be the area of the curve to the right of <span class="math inline">\(1.57\)</span>.</p>
<p>If you have a sample of <span class="math inline">\(n = 50\)</span>, then you would use a t-distribution with <span class="math inline">\(49\)</span> or <span class="math inline">\((n-1)\)</span> degrees of freedom.</p>
<p>An illustration is below:</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-93-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="how-to-calculate-p-values" class="section level3" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> How to calculate p-values</h3>
<p>In case you haven’t noticed by now, R has a default way of calculating probability areas…</p>
<p><em>IT ALWAYS CALCULATES AREAS FROM THE LEFT!</em></p>
<p>In other words, the default is to give you the area to the left of a number…</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="HT.html#cb166-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">Pval =</span> <span class="fu">pt</span>(<span class="fl">1.57</span>,<span class="dv">49</span>))</span></code></pre></div>
<pre><code>## [1] 0.9385746</code></pre>
<p>Don’t be annoyed about this, because all software does this (including Excel).</p>
<p>We can use this default to calculate the p-value (i.e. the area to the right of 1.57) in THREE different ways by relying on two properties of our probability distributions.</p>
<p><strong>Property 1:</strong> The distribution is centered at zero and symmetric.</p>
<p>This means that the area to the right of 1.57 is the same as the area to the left of -1.57. So we can use the pt function with the default setting to this effect:</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="HT.html#cb168-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">Pval =</span> <span class="fu">pt</span>(<span class="sc">-</span><span class="fl">1.57</span>,<span class="dv">49</span>))</span></code></pre></div>
<pre><code>## [1] 0.06142544</code></pre>
<p><strong>Property 2:</strong> The distribution always adds up to one.</p>
<p>This means that you have a 100% chance of pulling a number between negative and positive infinity. So if you use 1.57 and the default setting which gives you the area to the left, then subtract that number from 1 to get the area to the right:</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="HT.html#cb170-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">Pval =</span> <span class="dv">1</span><span class="sc">-</span><span class="fu">pt</span>(<span class="fl">1.57</span>,<span class="dv">49</span>))</span></code></pre></div>
<pre><code>## [1] 0.06142544</code></pre>
<p><strong>Final Option: Undo the default setting…</strong></p>
<p>The full command for calculating a p-value from a t-distribution (for our purposes) is as follows:</p>
<p>pt(q, df, lower.tail = TRUE)</p>
<p>Note that <span class="math inline">\(q\)</span> is the <em>quantity</em>, and <span class="math inline">\(df\)</span> is the <em>degrees of freedom</em>. All other entries (if not specified) go to their default values. This is where <span class="math inline">\(lower.tail\)</span> comes in. It is set to <em>TRUE</em> by default, meaning that whatever number you input for q, you will get the area to the left. If you change this entry to <em>FALSE</em>, then the default is switched off and you will calculate the area to the right.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="HT.html#cb172-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">Pval =</span> <span class="fu">pt</span>(<span class="fl">1.57</span>,<span class="dv">49</span>,<span class="at">lower.tail =</span> <span class="cn">FALSE</span>))</span></code></pre></div>
<pre><code>## [1] 0.06142544</code></pre>
<p>Notice that all three ways of calculating a p-value give you the exact same result. Therefore, you do not need to master all three - just pick whichever method works best for you.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>Note the language - significantly changed means that the value could have either gone up or down. This is why it is a two-sided test.<a href="HT.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="CI.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="SLR.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sjdres/MBA8350_Companion/edit/master/06-HT.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/sjdres/MBA8350_Companion/blob/master/06-HT.Rmd",
"text": null
},
"download": ["bookdownproj.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
